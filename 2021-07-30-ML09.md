---
layout: post
title: 기계학습09 - SVM
categories: [Today i learn]
tags: [TIL, AI]
description: 서포트 벡터 머신.
---

### 1. SVM Cost Function

---

![image-20210730005514867](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210730005514867.png)

- C는 람다의 역수이다. constant m을 제거한다. 상수가 있던 말던 동일하다.

- constraint가 있는 min을 풀기 위해 라그랑주를 사용한다.

### 2. Large Margin

---

![image-20210730010142221](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210730010142221.png)

- Decision boundary가 1보다 클 때만 1이고, 작으면 0인식.

![image-20210730010333218](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210730010333218.png)

- C가 매우크면 중심 식이 0이 되면서 우측만 남는다.

---

![image-20210730010521412](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210730010521412.png)

- C가 매우 크면 람다가 매우 작아져서 오버피팅 된다.
- C가 매우 작으면 검은선으로 간다.

### 3. Mathematics

---

![image-20210730010616645](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210730010616645.png)

- 이너 프로덕트를 하면 p는 v를 u로 정사영할때의 길이이다.
- p는 음수값이 나올수도 있다.

---

![image-20210730010904487](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210730010904487.png)

- C가 엄청 크다고 가정했을 때.

![image-20210730011002864](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210730011002864.png)

- 직교방향으로 쎄타값이 만들어진다.
- 파란색으로 X가 투영된다.p가 커져야한다.

### 4. Kernel

---

![image-20210730011706866](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210730011706866.png)

- linear하게 안되니까 f라는 것을 매핑해서 새로운 feature들을 만들었다.

---

![image-20210730011731147](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210730011731147.png)

- 랜드 마크의 디스턴스를 새로운 feature로 볼수도 있다.
- 가우시안 커널(RBF). l과 가까우면 1이 되고 떨어지면 0에 가까워진다. 

![image-20210730011935354](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210730011935354.png)

- 시그마를 컨트롤 파라메터로 쓸 수 있다. 작으면 슈퍼가우시안, 크면 넓어진다.

- 암 환자같은 것을 찾을 때 랜드마크로 쓸 수 있다?(negative 수집)

---

![image-20210730012106177](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210730012106177.png)

- 랜드 마크를 트레이닝 개수만큼 확보했다.
- 랜드 마크가 m만큼 생겼으니 m이 되고, x는 f로 해줘야한다.
- 시그마가 크면 high bias(펑퍼짐해진다), 작으면 high variance인 경향이 있다.
- 가우시안 커널 쓰기 전에 feature scaling을 하여라.





