---
layout: post
title: 기계학습14 - CNN[완]
categories: [Today i learn]
tags: [TIL, AI]
description: 뉴럴넷에 아주 간략히.
---

### 1. Convolutional Layer

---

![image-20210730103810327](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210730103810327.png)

![image-20210730103937164](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210730103937164.png)

- 필터가 영상을 훑는다.

### 2. Activation Functions

---

![image-20210730103907513](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210730103907513.png)

### 3. Max Pooling

---

![image-20210730104016616](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210730104016616.png)

- 제일 큰걸 고르는 것을 볼 수 있다.

### 3. Drop out

---

![image-20210730104212406](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210730104212406.png)

- Natural Language에서 쓴다.

### 4. VGGNET

---

![image-20210730104303385](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210730104303385.png)

- conv - batch normalization - Relu
- Batch Normalization을 쓰면 vanishing gradient 문제를 해결할 수 있다.

