---
layout: post
title: 기계학습01 - Model Representation
categories: [Today i learn]
tags: [TIL, AI]
description: Linear Regression
---

### 1. Model Representation

---

![image-20210729015024293](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729015024293.png)

- 가장 잘 예측하는 셉타를 찾는 것이 목적이다.

![image-20210729015109490](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729015109490.png)

- 스퀘어 에러가 최소가되는 부분을 찾아내면 된다. 이를 Cost function이라고 하자.

---

![image-20210729015222704](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729015222704.png)

- 오차값을 그려보면 2차 함수 형태를 띈다.
- 미분을 하면 알 수 있다. 하지만 local minimum에 빠질 수도 있는데, 이 때는 learning rate를 높게 주면 된다.

![image-20210729015344919](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729015344919.png)

- 다만 알파값을 너무 높이면 overshoot 될수도 있다.

---

![image-20210729015638089](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729015638089.png)

- 위의 Gradient descent algorithm과 Linear Regression Model을 합치면, 이런식으로 식을 유도할 수 있다.

![image-20210729015908262](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729015908262.png)