---
layout: post
title: 기계학습06 - Backpropagation
categories: [Today i learn]
tags: [TIL, AI]
description: 역전파. 아주 어려운.
---

### 1. Cost function

---

![image-20210729211859263](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729211859263.png)

- m은 traning의 개수, k는 class의 개수, L은 레이어의 토탈 개수, S1는 1레이어의 유닛의 개수
- h(x) 는 R^k 형태로 나온다.

### 2. Backpropagation

---

![image-20210729212939239](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729212939239.png)

- 마지막 레이어는 a - y
- 전체 오차를 가중치로 편미분한 값을 기존의 가중치에서 빼서 오차를 줄여나간다.

![image-20210729213334523](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729213334523.png)

![image-20210729213449478](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729213449478.png)

- 로지스틱 리그레션이 미분된 상태.

---

![image-20210729213803073](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729213803073.png)

- 노드로 들어온 신호에 그 노드의 편미분을 곱한 후 다음 노드에 전달한다. 

---

![image-20210729213537257](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729213537257.png)

![image-20210729214114197](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729214114197.png)

### 3. 역전파 알고리즘

---

![image-20210729214203714](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729214203714.png)

---

- 셉타값이 0으로 초기화하면 델타도 0이 되어버린다. 
- 셉타가 다 1이면 델타값도 동일해져서 서로 달라야한다.(랜덤값을 줘야한다)
- 작은 값들을 주어야한다. weight가 크면 exploding이 생긴다.

### 4. 뉴럴넷 학습

---

1. weight를 랜덤하게 초기화한다.
2. forward propagation을 돌린다.
3. J 세타를 계산한다.
4. backprop를 편미분을 통해 계산한다.
5. gradient checking을 해서 backpro와 비교한다.

---

- 다시봐도 뭔소리인지 알아먹기 힘들다.



