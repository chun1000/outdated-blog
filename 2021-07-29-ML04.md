---
layout: post
title: 기계학습04 - 오버피팅
categories: [Today i learn]
tags: [TIL, AI]
description: 오버피팅에 대해서.
---

### 1. Overfitting

---

- 너무 과도한 피쳐나 다항방정식을 사용한 경우.
- High variance라고도 한다.
- 에러가 0이라서 조금만 벗어나도 제대로 동작하지 못한다.

---

![image-20210729122407823](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729122407823.png)

![image-20210729122456085](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729122456085.png)

### 2. Overfitting에 대처하는 방법

---

- 특징의 수를 줄인다. 
- Regularization을 한다.

---

![image-20210729123332549](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729123332549.png)

- 셉타 3과 4에 큰 수를 곱하면 거의 0에 가까워진다.

![image-20210729123358360](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729123358360.png)

- 오른쪽 스퀘어 값이 minimal 해질 것이다. 
- j=1 부터 시작하는데, 셉타 0는 bias term이라서 overfitting될 가능성이 없다.

---

- 람다값이 작으면 오버피팅될 가능성이 높다.
- 람다값이 크면 셉타가 거의 0에 가까워지면서 언더피팅된다.

---

![image-20210729123825030](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729123825030.png)

### 3. Normal Equation

---

![image-20210729124016485](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729124016485.png)

- 노말 이퀘이션에도 넣을  수 있다.

### 4. Logistic Regression

---

![image-20210729124457716](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729124457716.png)

![image-20210729124509192](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729124509192.png)

- 그래디언트까지 동일하다. 1부터 n까지 하는 것만 주의.

