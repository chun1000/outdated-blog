---
layout: post
title: 기계학습02 - Linear Regression
categories: [Today i learn]
tags: [TIL, AI]
description: 선형회귀분석.
---

### 1.  Multiple Features

---

![image-20210729020419718](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729020419718.png)

![image-20210729020443966](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729020443966.png)

### 2. Feature Scaling

---

![image-20210729020523602](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729020523602.png)

- 한쪽 값이 너무 커서 찌그러지면 한쪽 기울기가 급해진다. 이를 위해서 Feature Scaling을 한다.(큰값에 bias될 가능성이 있다.)

![image-20210729020627401](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729020627401.png)

---

- normalization
  - 고등학생 때 많이 하던 그거.

![image-20210729020646338](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729020646338.png)

### 3. Learning Rate

---

![image-20210729020735519](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729020735519.png)

- 위 그림처럼 떨어지는게 가장 이상적이다.
- 그래프가 위로 올라가거나, 내려갔다 올라갔다가 왔다갔다하면 러닝 레잇이 너무 큰 경우이다.
- 작은걸로 하면 잘 안떨어질 수 있다.(local minimum)

### 4. Polynomial Regression

---

![image-20210729020849676](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729020849676.png)

- 오버피팅 될수도 있다.

### 5. Normal Equation

---

![image-20210729020928622](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729020928622.png)

![image-20210729021138345](https://raw.githubusercontent.com/chunyunseo/ImageRepo/image/img/image-20210729021138345.png)

- 한방에 풀 수 있다. 대신 엄청나게 느리다.
- theta = pinv(x'\*x)\*x'\*y
- inverse 구하는건 언제나 어렵다.

